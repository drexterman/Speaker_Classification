# -*- coding: utf-8 -*-
"""speaker_identification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yzWX7rvyE_8XTRdRO-v8jgHljns4i9s
"""

import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.model_selection import train_test_split
import librosa
import librosa.display

from google.colab import drive
drive.mount('/content/drive')

!pip install librosa==0.9.2

audio_folder = '/content/drive/My Drive/GMM-Speaker-Identification-data/Speaker_data/Voice_Samples_Training'
speakers = os.listdir(audio_folder)
print(f"Speakers in the dataset: {speakers}")

#X_train, X_test, y_train, y_test = train_test_split(audio_files, labels, test_size=0.2, random_state=42)

audio_files = []
labels = []
# ... (Populate audio_files and labels based on your folder structure)
for speaker in speakers:
    speaker_folder = os.path.join(audio_folder, speaker)
    for file_name in os.listdir(speaker_folder):
        if file_name.endswith('.wav'):  # Adjust file extension if needed
            file_path = os.path.join(speaker_folder, file_name)
            audio_files.append(file_path)
            labels.append(speaker)
print(len(labels))
print(audio_files)

def extract_mfcc(file):
  y, sr = librosa.load(file)
  mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Adjust n_mfcc as needed
  return mfccs.T  # Transpose for GMM

X_train = [extract_mfcc(file) for file in audio_files]
print(X_train)

m=min(len(X_train[i]) for i in range(len(X_train)))
print(m)
X_train=[X_train[i][:m] for i in range(len(X_train))]
X_train=np.array(X_train)
print(X_train.shape)

from sklearn.mixture import GaussianMixture
gmm_models = {}
for speaker in speakers:
  speaker_data = [X_train[i] for i, label in enumerate(labels) if label == speaker]
  speaker_data = np.concatenate(speaker_data, axis=0)
  print(len(speaker_data))
  gmm_models[speaker] = GaussianMixture(n_components=16, covariance_type='diag').fit(speaker_data) # Adjust parameters

def predict_speaker(audio_file):
  mfccs = extract_mfcc(audio_file)
  #mfcc=mfcc[:m]
  scores = {speaker: gmm.score(mfccs) for speaker, gmm in gmm_models.items()}
  predicted_speaker = max(scores, key=scores.get)
  return predicted_speaker

for i in range(len(audio_files)):
  print(predict_speaker(audio_files[i]))

import re

audio_folder = '/content/drive/My Drive/GMM-Speaker-Identification-data/Speaker_data/Testing_Audio'
speakers = os.listdir(audio_folder)
print(f"Speakers in the dataset: {speakers}")

audio_files = []
labels = []
# ... (Populate audio_files and labels based on your folder structure)
for speaker in speakers:
    speaker_folder = os.path.join(audio_folder, speaker)
    if not os.path.isdir(speaker_folder):
      audio_files.append(speaker_folder)
      labels.append(re.split('[-_.]', speaker)[0])
      continue
    for file_name in os.listdir(speaker_folder):
        if file_name.endswith('.wav'):  # Adjust file extension if needed
            file_path = os.path.join(speaker_folder, file_name)
            audio_files.append(file_path)
            labels.append(re.split('[-_.]', speaker)[0])
print(labels)
print(audio_files)

predictions=[]
for i in range(len(audio_files)):
  predictions.append(predict_speaker(audio_files[i]))

wrong=0
for i in range(len(predictions)):
  p=re.split('[-_.]', predictions[i])[0]
  if labels[i][0]=='P':
    continue
  print(f"Predicted speaker: {p} , {labels[i]}")
  if p!=labels[i]:
    wrong+=1
print(wrong/len(predictions))

print(f"Accuracy = {(1-(wrong/len(predictions)))*100}%")